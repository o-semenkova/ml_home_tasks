import os
from typing import Dict, Any, List, Optional
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.metrics import (
    confusion_matrix, ConfusionMatrixDisplay,
    roc_curve, RocCurveDisplay,
    roc_auc_score, f1_score
)
import matplotlib.pyplot as plt


# -------------------- Ð”ÐžÐŸÐžÐœÐžÐ–ÐÐ† Ð¤Ð£ÐÐšÐ¦Ð†Ð‡ --------------------

def _add_features(df: pd.DataFrame) -> pd.DataFrame:
    """Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ Ð²ÑÑ– Ð¿Ð¾Ñ…Ñ–Ð´Ð½Ñ– Ñ„Ñ–Ñ‡Ñ– Ð”Ðž ÑÐ¿Ð»Ñ–Ñ‚Ñƒ."""
    df = df.copy()

    # Drop Ñ‚ÐµÑ…Ð½Ñ–Ñ‡Ð½Ð¸Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
    df = df.drop(['id', 'CustomerId', 'Surname'], axis=1, errors='ignore')

    # Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ ProductGroup
    def simplify_products(x: int) -> str:
        if x == 1:
            return '1'
        elif x == 2:
            return '2'
        else:
            return '3'

    df['ProductGroup'] = df['NumOfProducts'].apply(simplify_products)

    return df


def _scale(train_df: pd.DataFrame, other_df: pd.DataFrame,
           numeric_cols: List[str]):
    scaler = MinMaxScaler()
    scaler.fit(train_df[numeric_cols])

    train_scaled = train_df.copy()
    other_scaled = other_df.copy()

    train_scaled[numeric_cols] = scaler.transform(train_df[numeric_cols])
    other_scaled[numeric_cols] = scaler.transform(other_df[numeric_cols])

    return train_scaled, other_scaled, scaler


def _encode(train_df: pd.DataFrame, other_df: pd.DataFrame,
            cat_cols: List[str]):
    encoder = OneHotEncoder(drop='first', sparse_output=False)
    encoder.fit(train_df[cat_cols])

    train_encoded = pd.DataFrame(
        encoder.transform(train_df[cat_cols]),
        columns=encoder.get_feature_names_out(cat_cols),
        index=train_df.index
    )

    other_encoded = pd.DataFrame(
        encoder.transform(other_df[cat_cols]),
        columns=encoder.get_feature_names_out(cat_cols),
        index=other_df.index
    )

    return train_encoded, other_encoded, encoder


# -------------------- ÐžÐ¡ÐÐžÐ’ÐÐ Ð¤Ð£ÐÐšÐ¦Ð†Ð¯ --------------------

def preprocess_data(
        raw_df: pd.DataFrame,
        save_dir="models",
        scaler_numeric=True,
        test_size=0.1,
) -> Dict[str, Any]:

    os.makedirs(save_dir, exist_ok=True)

    # 1) Ð”ÐžÐ”ÐÐ„ÐœÐž Ð¤Ð†Ð§Ð† Ð”Ðž Ð¡ÐŸÐ›Ð†Ð¢Ð£
    df = _add_features(raw_df)

    target_col = "Exited"
    numeric_cols = ['Age', 'NumOfProducts', 'IsActiveMember', 'Balance']
    categorical_cols = ['Geography', 'Gender', 'ProductGroup']

    # 2) Ð¡ÐŸÐ›Ð†Ð¢
    train_val_df, test_df = train_test_split(
        df,
        test_size=test_size,
        random_state=42,
        stratify=df[target_col]
    )

    train_df, val_df = train_test_split(
        train_val_df,
        test_size=0.2,
        random_state=42,
        stratify=train_val_df[target_col]
    )

    # 3) Ð’Ð˜Ð”Ð†Ð›Ð¯Ð„ÐœÐž Y
    y_train, y_val, y_test = (
        train_df[target_col].copy(),
        val_df[target_col].copy(),
        test_df[target_col].copy(),
    )

    # Ð’Ð¸Ð´Ð°Ð»ÑÑ”Ð¼Ð¾ Ñ‚Ð°Ñ€Ð³ÐµÑ‚ Ð· X
    train_df = train_df.drop(columns=[target_col])
    val_df = val_df.drop(columns=[target_col])
    test_df = test_df.drop(columns=[target_col])

    # 4) ÐœÐ°ÑÑˆÑ‚Ð°Ð±ÑƒÐ²Ð°Ð½Ð½Ñ (Ð±ÐµÐ· leakage)
    scaler = None
    if scaler_numeric:
        train_df, val_df, scaler = _scale(train_df, val_df, numeric_cols)
        _, test_df, _ = _scale(train_df, test_df, numeric_cols)
    else:
        print("ðŸš« ÐœÐ°ÑÑˆÑ‚Ð°Ð±ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¸Ñ… Ð¾Ð·Ð½Ð°Ðº Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾.")

    # 5) One-Hot Encoding (Ð±ÐµÐ· leakage)
    train_encoded, val_encoded, encoder = _encode(train_df, val_df, categorical_cols)
    _, test_encoded, _ = _encode(train_df, test_df, categorical_cols)

    # 6) ÐžÐ±â€™Ñ”Ð´Ð½Ð°Ð½Ð½Ñ Ñ„Ñ–Ð½Ð°Ð»ÑŒÐ½Ð¸Ñ… Ñ„Ñ–Ñ‡
    X_train = pd.concat([train_df.drop(columns=categorical_cols), train_encoded], axis=1)
    X_val = pd.concat([val_df.drop(columns=categorical_cols), val_encoded], axis=1)
    X_test = pd.concat([test_df.drop(columns=categorical_cols), test_encoded], axis=1)

    input_cols = list(X_train.columns)

    # 7) Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ preprocessors
    if scaler:
        joblib.dump(scaler, f"{save_dir}/scaler.joblib")
    joblib.dump(encoder, f"{save_dir}/encoder.joblib")

    print("âœ… ÐŸÑ€ÐµÐ¿Ñ€Ð¾Ñ†ÐµÑ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾")

    return {
        'train_X': X_train,
        'train_y': y_train,
        'val_X': X_val,
        'val_y': y_val,
        'test_X': X_test,
        'test_y': y_test,
        'input_cols': input_cols,
        'scaler': scaler,
        'encoder': encoder,
    }


# -------------------- Ð¢Ð ÐÐÐ¡Ð¤ÐžÐ ÐœÐÐ¦Ð†Ð¯ ÐÐžÐ’Ð˜Ð¥ Ð”ÐÐÐ˜Ð¥ --------------------

def transform_new_data(new_df: pd.DataFrame,
                       preprocessors: Dict[str, Optional[Any]]):
    df = _add_features(new_df)

    numeric_cols = ['Age', 'NumOfProducts', 'IsActiveMember', 'Balance']
    categorical_cols = ['Geography', 'Gender', 'ProductGroup']

    scaler = preprocessors.get("scaler")
    encoder: OneHotEncoder = preprocessors.get("encoder")

    if scaler:
        df[numeric_cols] = scaler.transform(df[numeric_cols])

    encoded = pd.DataFrame(
        encoder.transform(df[categorical_cols]),
        columns=encoder.get_feature_names_out(categorical_cols),
        index=df.index
    )

    df = pd.concat([df.drop(columns=categorical_cols), encoded], axis=1)
    return df

# -------------------- ÐžÐ¦Ð†ÐÐšÐ ÐœÐžÐ”Ð•Ð›Ð† --------------------

def evaluate_model_from_proba(y_true, y_proba, dataset_name='Dataset'):
    """
    ÐžÑ†Ñ–Ð½ÑŽÑ” Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð·Ð° Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¼Ð¸ true labels Ñ‚Ð° predicted probabilities.

    Args:
        y_true (array-like): Ð ÐµÐ°Ð»ÑŒÐ½Ñ– Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ñ†Ñ–Ð»ÑŒÐ¾Ð²Ð¾Ñ— Ð·Ð¼Ñ–Ð½Ð½Ð¾Ñ— (0/1).
        y_proba (array-like): ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¾Ð²Ð°Ð½Ñ– Ð¹Ð¼Ð¾Ð²Ñ–Ñ€Ð½Ð¾ÑÑ‚Ñ– ÐºÐ»Ð°ÑÑƒ 1.
        dataset_name (str): ÐÐ°Ð·Ð²Ð° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñƒ Ð´Ð»Ñ Ð¿Ñ–Ð´Ð¿Ð¸ÑÑ–Ð² Ð³Ñ€Ð°Ñ„Ñ–ÐºÑ–Ð².
    """

    # 1. ÐŸÐµÑ€ÐµÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¿Ð¾Ñ€Ð¾Ð³Ñƒ 0.5 Ð½Ð° ÐºÐ»Ð°ÑÐ¸
    y_pred = (y_proba >= 0.5).astype(int)

    # 2. Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.title(f'Confusion Matrix: {dataset_name}')
    plt.show()

    # 3. ROC Curve
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    RocCurveDisplay(fpr=fpr, tpr=tpr).plot()
    plt.title(f'ROC Curve: {dataset_name}')
    plt.show()

    # 4. ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸
    auc = roc_auc_score(y_true, y_proba)
    f1 = f1_score(y_true, y_pred)

    print(f"ðŸ“Š {dataset_name} â€” AUROC: {auc:.3f}, F1 Score (threshold=0.5): {f1:.3f}")

