import os
import pandas as pd
from typing import Tuple, Optional, List
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
import joblib


# -------------------- –í–ù–£–¢–†–Ü–®–ù–Ü –ü–Ü–î–§–£–ù–ö–¶–Ü–á --------------------

def _drop_unused_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    –í–∏–¥–∞–ª—è—î —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –∞–±–æ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ–π–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏, –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ.

    Args:
        df (pd.DataFrame): –í—Ö—ñ–¥–Ω–∏–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º.

    Returns:
        pd.DataFrame: –î–∞—Ç–∞—Ñ—Ä–µ–π–º –±–µ–∑ —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.
    """
    return df.drop(['id', 'CustomerId', 'Surname'], axis=1, errors='ignore')


def _add_product_group(df: pd.DataFrame) -> pd.DataFrame:
    """
    –°—Ç–≤–æ—Ä—é—î –Ω–æ–≤—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—É –æ–∑–Ω–∞–∫—É 'ProductGroup' –Ω–∞ –æ—Å–Ω–æ–≤—ñ 'NumOfProducts'.

    Args:
        df (pd.DataFrame): –í—Ö—ñ–¥–Ω–∏–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —ñ–∑ –∫–æ–ª–æ–Ω–∫–æ—é NumOfProducts.

    Returns:
        pd.DataFrame: –ö–æ–ø—ñ—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É –∑ –¥–æ–¥–∞–Ω–æ—é –∫–æ–ª–æ–Ω–∫–æ—é 'ProductGroup'.
    """
    def simplify_products(x: int) -> str:
        if x == 1:
            return '1'
        elif x == 2:
            return '2'
        else:
            return '3'

    df['ProductGroup'] = df['NumOfProducts'].apply(simplify_products)
    return df


def _scale_numeric_features(
    train_df: pd.DataFrame, val_df: pd.DataFrame, numeric_cols: List[str]
) -> Tuple[pd.DataFrame, pd.DataFrame, MinMaxScaler]:
    """
    –ú–∞—Å—à—Ç–∞–±—É—î —á–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é MinMaxScaler.

    Args:
        train_df (pd.DataFrame): –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π –Ω–∞–±—ñ—Ä.
        val_df (pd.DataFrame): –í–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏–π –Ω–∞–±—ñ—Ä.
        numeric_cols (List[str]): –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤ —á–∏—Å–ª–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.

    Returns:
        Tuple[pd.DataFrame, pd.DataFrame, MinMaxScaler]:
            –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ train —ñ val –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∏, –∞ —Ç–∞–∫–æ–∂ scaler.
    """
    scaler = MinMaxScaler()
    scaler.fit(train_df[numeric_cols])

    train_scaled = train_df.copy()
    val_scaled = val_df.copy()

    train_scaled[numeric_cols] = scaler.transform(train_df[numeric_cols])
    val_scaled[numeric_cols] = scaler.transform(val_df[numeric_cols])

    return train_scaled, val_scaled, scaler


def _encode_categorical_features(
    train_df: pd.DataFrame, val_df: pd.DataFrame, categorical_cols: List[str]
) -> Tuple[pd.DataFrame, pd.DataFrame, OneHotEncoder, List[str]]:
    """
    –í–∏–∫–æ–Ω—É—î One-Hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫.

    Args:
        train_df (pd.DataFrame): –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π –Ω–∞–±—ñ—Ä.
        val_df (pd.DataFrame): –í–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏–π –Ω–∞–±—ñ—Ä.
        categorical_cols (List[str]): –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.

    Returns:
        Tuple[pd.DataFrame, pd.DataFrame, OneHotEncoder, List[str]]:
            –ó–∞–∫–æ–¥–æ–≤–∞–Ω—ñ train —ñ val –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∏, encoder —ñ —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤ –Ω–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.
    """
    encoder = OneHotEncoder(drop='first', sparse_output=False)
    encoder.fit(train_df[categorical_cols])

    encoded_cols = encoder.get_feature_names_out(categorical_cols)

    train_encoded = pd.DataFrame(
        encoder.transform(train_df[categorical_cols]),
        columns=encoded_cols,
        index=train_df.index
    )

    val_encoded = pd.DataFrame(
        encoder.transform(val_df[categorical_cols]),
        columns=encoded_cols,
        index=val_df.index
    )

    return train_encoded, val_encoded, encoder, list(encoded_cols)


# -------------------- –ü–£–ë–õ–Ü–ß–ù–Ü –§–£–ù–ö–¶–Ü–á --------------------

def preprocess_data(
    raw_df: pd.DataFrame,
    save_dir: str = "models",
    scaler_numeric: bool = True
) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series, List[str], Optional[MinMaxScaler], OneHotEncoder]:
    """
    –ü–æ–≤–Ω–∞ –ø–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –∑–∞–¥–∞—á—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –≤—ñ–¥—Ç–æ–∫—É –∫–ª—ñ—î–Ω—Ç—ñ–≤ –±–∞–Ω–∫—É.

    Args:
        raw_df (pd.DataFrame): –°–∏—Ä–∏–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º.
        save_dir (str): –¢–µ–∫–∞ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–æ—Ä—ñ–≤.
        scaler_numeric (bool): –ß–∏ –º–∞—Å—à—Ç–∞–±—É–≤–∞—Ç–∏ —á–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏ (–¥–ª—è –¥–µ—Ä–µ–≤ False).

    Returns:
        Tuple: X_train, y_train, X_val, y_val, input_cols, scaler, encoder
    """
    os.makedirs(save_dir, exist_ok=True)

    df = _drop_unused_columns(raw_df)
    target_col = 'Exited'

    train_df, val_df = train_test_split(
        df, test_size=0.2, random_state=42, stratify=df[target_col]
    )

    numeric_cols = ['Age', 'NumOfProducts', 'IsActiveMember', 'Balance']
    categorical_cols = ['Geography', 'Gender', 'ProductGroup']

    train_df = _add_product_group(train_df)
    val_df = _add_product_group(val_df)

    scaler: Optional[MinMaxScaler] = None
    if scaler_numeric:
        train_df, val_df, scaler = _scale_numeric_features(train_df, val_df, numeric_cols)
        print("üìè –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è —á–∏—Å–ª–æ–≤–∏—Ö –æ–∑–Ω–∞–∫ —É–≤—ñ–º–∫–Ω–µ–Ω–æ.")
    else:
        print("üö´ –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è —á–∏—Å–ª–æ–≤–∏—Ö –æ–∑–Ω–∞–∫ –≤–∏–º–∫–Ω–µ–Ω–æ.")

    train_encoded, val_encoded, encoder, encoded_cols = _encode_categorical_features(
        train_df, val_df, categorical_cols
    )

    X_train = pd.concat([train_df.drop(columns=categorical_cols), train_encoded], axis=1)
    X_val = pd.concat([val_df.drop(columns=categorical_cols), val_encoded], axis=1)

    y_train = train_df[target_col]
    y_val = val_df[target_col]

    input_cols = X_train.columns.tolist()

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    if scaler is not None:
        joblib.dump(scaler, os.path.join(save_dir, "scaler.joblib"))
    joblib.dump(encoder, os.path.join(save_dir, "encoder.joblib"))
    print(f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ encoder (—ñ scaler, —è–∫—â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤—Å—è) —É '{save_dir}'")

    return X_train, y_train, X_val, y_val, input_cols, scaler, encoder


def load_preprocessors(save_dir: str = "models") -> Tuple[Optional[MinMaxScaler], Optional[OneHotEncoder]]:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∑–±–µ—Ä–µ–∂–µ–Ω—ñ scaler —Ç–∞ encoder —ñ–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó `save_dir`.

    Args:
        save_dir (str): –®–ª—è—Ö –¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ joblib-—Ñ–∞–π–ª–∞–º–∏.

    Returns:
        Tuple[Optional[MinMaxScaler], Optional[OneHotEncoder]]: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –æ–±‚Äô—î–∫—Ç–∏ –∞–±–æ None.
    """
    scaler_path = os.path.join(save_dir, "scaler.joblib")
    encoder_path = os.path.join(save_dir, "encoder.joblib")

    scaler = encoder = None

    if os.path.exists(encoder_path):
        encoder = joblib.load(encoder_path)
        print("‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ encoder")
    else:
        print(f"‚ö†Ô∏è  –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª: {encoder_path}")

    if os.path.exists(scaler_path):
        scaler = joblib.load(scaler_path)
        print("‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ scaler")
    else:
        print(f"‚ÑπÔ∏è  –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è, –π–º–æ–≤—ñ—Ä–Ω–æ, –Ω–µ –∑–∞—Å—Ç–æ—Å–æ–≤—É–≤–∞–ª–æ—Å—å ({scaler_path} –≤—ñ–¥—Å—É—Ç–Ω—ñ–π)")

    return scaler, encoder


def transform_new_data(
    new_df: pd.DataFrame,
    scaler: Optional[MinMaxScaler],
    encoder: OneHotEncoder
) -> pd.DataFrame:
    """
    –û–±—Ä–æ–±–ª—è—î –Ω–æ–≤—ñ –¥–∞–Ω—ñ —Ç–∏–º —Å–∞–º–∏–º —Å–ø–æ—Å–æ–±–æ–º, —â–æ –π —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ.

    Args:
        new_df (pd.DataFrame): –ù–æ–≤—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ (–±–µ–∑ –∫–æ–ª–æ–Ω–∫–∏ 'Exited').
        scaler (Optional[MinMaxScaler]): –ú–∞—Å—à—Ç–∞–±—É–≤–∞–ª—å–Ω–∏–∫ (–º–æ–∂–µ –±—É—Ç–∏ None).
        encoder (OneHotEncoder): –ö–æ–¥–µ—Ä –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö.

    Returns:
        pd.DataFrame: –û–±—Ä–æ–±–ª–µ–Ω–∏–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º, –≥–æ—Ç–æ–≤–∏–π –¥–ª—è –º–æ–¥–µ–ª—ñ.
    """
    df = new_df.copy()
    df = _drop_unused_columns(df)
    df = _add_product_group(df)

    numeric_cols = ['Age', 'NumOfProducts', 'IsActiveMember', 'Balance']
    categorical_cols = ['Geography', 'Gender', 'ProductGroup']

    if scaler:
        df[numeric_cols] = scaler.transform(df[numeric_cols])

    encoded_cols = encoder.get_feature_names_out(categorical_cols)
    encoded_array = encoder.transform(df[categorical_cols])
    encoded_df = pd.DataFrame(encoded_array, columns=encoded_cols, index=df.index)

    df_final = pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)
    return df_final
